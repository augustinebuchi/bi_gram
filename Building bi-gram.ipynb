{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d110be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Desktop\\Language Model\\cuda\\lib\\site-packages\\torch\\cuda\\__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 6050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #this is to show if cuda is available on the device being used.\n",
    "print(device)\n",
    "# import torch\n",
    "# device = 'cpu'\n",
    "# print(device)\n",
    "max_iters=1000\n",
    "# eval interval = 2500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 250\n",
    "#dropout = 0.2 is for dropping certain neurons to make model performance more accurate and avoid noises due to excessive neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c8b5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232307\n"
     ]
    }
   ],
   "source": [
    "with open('wiz_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))\n",
    "\n",
    "# Extract unique characters from the text\n",
    "chars = sorted(set(text))\n",
    "\n",
    "string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Function to encode a string\n",
    "def encode(s):\n",
    "    return [string_to_int[c] for c in s]\n",
    "\n",
    "# Function to decode a list of integers\n",
    "def decode(l):\n",
    "    return ''.join([int_to_string[i] for i in l if i in int_to_string])\n",
    "\n",
    "\n",
    "#just for testing\n",
    "# encoded_hello = encode('hello')\n",
    "# decoded_hello = decode(encoded_hello)\n",
    "# print(encoded_hello)\n",
    "# print(decoded_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ba426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,  1, 47,\n",
      "        33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26, 49,  0,\n",
      "         0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,  0,  0,\n",
      "         1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1, 47, 33,\n",
      "        50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1, 36, 25,\n",
      "        38, 28,  1, 39, 30,  1, 39, 50,  9,  1])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21440cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ed1d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[68, 74,  1, 71, 58, 66, 58, 66],\n",
      "        [65, 68, 76,  1, 76, 54, 72,  1],\n",
      "        [56, 73,  1, 76, 54, 72,  1, 73],\n",
      "        [59, 58, 76,  1, 57, 68, 79, 58]])\n",
      "targets: \n",
      "tensor([[74,  1, 71, 58, 66, 58, 66, 55],\n",
      "        [68, 76,  1, 76, 54, 72,  1, 65],\n",
      "        [73,  1, 76, 54, 72,  1, 73, 61],\n",
      "        [58, 76,  1, 57, 68, 79, 58, 67]])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    #print(ix)\n",
    "    x= torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    #x, y = x.to(device, y.to(device))\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "#print(x.shape)\n",
    "print(x)\n",
    "print('targets: ')\n",
    "print(y)\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab42203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is  tensor([80]) target is  tensor(28)\n",
      "when input is  tensor([80, 28]) target is  tensor(39)\n",
      "when input is  tensor([80, 28, 39]) target is  tensor(42)\n",
      "when input is  tensor([80, 28, 39, 42]) target is  tensor(39)\n",
      "when input is  tensor([80, 28, 39, 42, 39]) target is  tensor(44)\n",
      "when input is  tensor([80, 28, 39, 42, 39, 44]) target is  tensor(32)\n",
      "when input is  tensor([80, 28, 39, 42, 39, 44, 32]) target is  tensor(49)\n",
      "when input is  tensor([80, 28, 39, 42, 39, 44, 32, 49]) target is  tensor(1)\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print('when input is ', context, 'target is ', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3361e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None): #normal forward fnx for every model phase building created and defined\n",
    "        logits = self.token_embedding_table(index)\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    \n",
    "    def generate(self, index, max_new_tokens): #normal generate function for every model phase building created and defined\n",
    "        #index is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            #focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B,C)\n",
    "            #apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim =-1)# (B,C)\n",
    "            #sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            #append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c8644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "vocab_size = 10000  # Example value, replace with actual vocab size which is \\\n",
    "                    # 40,000 for my dataset, yours may be different with respect to your data.\\\n",
    "                    # I used 10,000 because my laptop is very poor in computationa power and also uses a cpu.\n",
    "model = BigramLanguageModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b2ba0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 6392, 6336, 8434,   49, 4141, 3431, 8421, 2070, 8282,  141, 4602,\n",
      "         5737, 7911, 2718, 3440, 1100,   71, 3674, 4730, 2617,  304, 2368, 1603,\n",
      "         2434, 6250, 6831, 3068, 6664, 2961, 3665, 7744, 2755,  411, 6854, 8036,\n",
      "         1149, 1753, 5079, 1034, 6416, 4524, 2408, 1977, 6101, 6318, 8458, 3446,\n",
      "         8986, 3823, 5563, 2273, 6890, 3998, 5643, 8111, 6090, 6381, 7692, 6947,\n",
      "         3048, 6326, 2758, 3479, 3830, 6453, 7786, 3416, 7207, 4969, 2861, 8366,\n",
      "         7542, 1714,  781, 9178, 6297, 9157, 4439, 5804, 9658, 2119, 6174, 4586,\n",
      "         3802, 6108, 3234, 6271, 3479, 6217, 2527, 3979, 1214, 8080, 7394, 1495,\n",
      "         4857, 6296,  216, 5194, 6147, 1473, 8419, 3719, 2032, 8361, 1645, 5090,\n",
      "         7622, 1764, 8699, 1095, 7855, 3717, 4119, 8736, 1902, 6648, 9098, 5244,\n",
      "         7465, 8364, 2129, 9685, 7323, 6289, 5111, 3408, 1096, 3603, 5067, 2913,\n",
      "         9302, 2990, 9004, 9180, 8376, 8524, 5524, 1102, 8809, 5340, 6812, 9684,\n",
      "         1127, 2352, 9409,  586, 3719, 6168, 5023, 7642, 6781, 9599, 6488, 8676,\n",
      "         9828, 5061, 2337, 1706, 8093, 5564, 8564, 7764,   51, 5352, 5111, 4326,\n",
      "          338, 3480, 4172, 5599, 8769, 5456,  444, 5036, 8892, 8361, 3250, 9632,\n",
      "         2850,  447, 4359, 5355, 8039, 6191, 6410,  672, 2859, 1800,  520, 5407,\n",
      "         9238, 7697, 1544, 3231, 2363, 9316, 4265, 2860, 5654, 3158, 1949, 1975,\n",
      "         7739, 8966, 7847, 8916, 5960, 1781,  440, 4625, 4539, 6108, 5094, 6676,\n",
      "         1886, 8983, 9558, 3008, 2640, 5687, 6122, 2857, 6283, 3468, 2125, 2527,\n",
      "         8580, 3309, 5851, 6396, 2703, 9467, 7709, 3484, 4900, 4520, 8004, 5942,\n",
      "         5127, 8386, 5770, 8676, 8202, 1517,  709, 8759, 4482,  253, 2577, 1505,\n",
      "         6140, 2176, 2530, 4113, 7258, 8525, 3798, 7291,  750, 7108, 9994, 8224,\n",
      "         6970, 9974, 6497, 1021,  696, 7634, 1817,    5, 9551, 1586, 7565,  889,\n",
      "         3141, 9482, 3750, 2993, 1133, 3810, 9646, 5117, 9752, 7196, 6771, 5077,\n",
      "         2392,  706, 5934, 7149, 3420,  965, 3190,  716, 1388, 6593, 1800, 7049,\n",
      "         2408, 9059, 1939, 6729, 3594,  333, 1830, 2548, 2901, 8788, 1348, 7951,\n",
      "         4776, 8027, 1843, 6414, 2463, 1861, 7114, 1140, 4534, 2582, 2104, 6371,\n",
      "         1859, 2196, 5232, 9851, 9098, 7724, 8277, 7877, 8744,  681, 6386, 2266,\n",
      "         4838,   27,  683, 1157, 4856, 9699, 2785, 1270, 8185, 3296, 8176, 5766,\n",
      "         9751, 3050, 9701, 8482,  882,  356, 9780, 7657, 1486, 9107, 5321, 9542,\n",
      "         8899, 9492, 4489, 8135, 6425, 4385, 7248, 4588, 4740, 9950, 7124, 3940,\n",
      "         1925,  920, 3068,  623,  129, 4403, 9997,  173, 9383,  307, 2434, 2539,\n",
      "         1920, 7237, 9639, 4121, 9828, 9006, 5570,  123, 1296, 1597, 4359, 9278,\n",
      "          943, 3479, 7110, 4019, 3919, 1220, 7568, 3853, 6140, 6727, 5933, 4491,\n",
      "         7702, 3155, 2107, 4618, 1488, 5886, 8386, 1391, 8432, 7306, 3388, 3507,\n",
      "         4599,  126,  834, 7844,  989, 8257, 9261, 6497, 7241, 6104, 1864, 2903,\n",
      "         3938,  142, 5107, 8458, 8500, 4341, 7372, 3137, 7400, 4010, 1194, 5322,\n",
      "          825, 7305, 9686, 6180, 6309, 1329, 2355, 6256, 6695,  539, 2320, 6892,\n",
      "         2681, 8673, 1625, 6050, 2041, 8840, 9944, 9403, 4511, 3349, 6605, 3092,\n",
      "         6549,  788, 3221, 9722, 8893, 1693, 6654, 5337, 1314, 2965, 7782, 7406,\n",
      "         1199, 8511, 1269, 8843, 3760, 7419, 6390, 8430, 2572, 8360, 9482, 2990,\n",
      "         6394, 7485, 4817, 3781, 1509, 4319, 2186, 5405, 2942]])\n"
     ]
    }
   ],
   "source": [
    "# Define context and generate text\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_chars = model.generate(context, max_new_tokens=500)\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    \n",
    "#     if iter % eval_iters ==0:\n",
    "#         #something soon now...\n",
    "#         print(f'step: {iter}, loss{losses}')\n",
    "    \n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    #evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device = device)\n",
    "generated_chars = decode(model.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)\n",
    "\n",
    "# #there's this no_grad way for training, it enables space saving in storage, training without gradient computations.\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        X, Y = get_batch(split)\n",
    "        logits, loss=model(X,Y)\n",
    "        losses[k] = loss.item()\n",
    "        out[spli]=losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf409e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Language Model (cuda)",
   "language": "python",
   "name": "language_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
